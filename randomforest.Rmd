```{r hw4_setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
```

# Homework 4

## Required Analysis

For this homework,

1. **Specify the research question for a classification task.**

Can we predict the continent the observation comes from?

2. **Try to implement at least 2 different classification methods to answer your research question.**

1. Decision tree
2. 

3. **Reflect on the information gained from these two methods and how you might justify this method to others.**

#### Your Work {-}

```{r}
# library statements 
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
library(lubridate)
library(gridExtra)
library(vip)
library(ranger)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
conflicted::conflict_prefer("vi", "vip")

# read in data
covid <- read_csv("owid-covid-data.csv")
```
```{r}
nafun <- function(x) {
  
}
```


```{r}
# data cleaning
covid <- covid %>%
  filter(date >= as.Date("2021-08-13"))%>%
  select(-icu_patients, -icu_patients_per_million, -hosp_patients, -hosp_patients_per_million, -weekly_icu_admissions, -weekly_icu_admissions_per_million, -weekly_hosp_admissions, -weekly_hosp_admissions_per_million, -total_tests, -total_tests_per_thousand, -new_tests_smoothed, -new_tests_smoothed_per_thousand, -handwashing_facilities, -excess_mortality_cumulative_absolute, -excess_mortality_cumulative, -excess_mortality, -excess_mortality_cumulative_per_million, -male_smokers, -female_smokers, -hospital_beds_per_thousand, -extreme_poverty, -location)

# SHOULD WE REMOVE LOCATION?
```

```{r}
covid <- covid %>%
  na.omit(covid) %>%
  filter(continent %in% c("North America", "Asia", "South America", "Africa", "Europe", "Oceania")) %>%
  mutate(continent = factor(continent))
```

- We're considering COVID cases occurring after the first recorded booster vaccines (13th August, 2021) to best capture today's landscape.  
- This is when vaccinations started to become widespread (at least in the United States).
- In addition to our existing variables, we also added the following to our model to predict the continent:
    - `life_expectancy`
    - `population_density`
    - `median_age`
    - `gdp_per_capita`
    



```{r}
# Bagging and Random Forest

# Model Specification
rf_spec <- rand_forest() %>%
  set_engine(engine = 'ranger') %>% 
  set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(ncol(x)))
           trees = 1000, # Number of trees
           min_n = 2,
           probability = FALSE, # FALSE: hard predictions
           importance = 'impurity') %>% 
  set_mode('classification') # change this for regression tree

# Recipe

rf_rec <- recipe(continent ~ ., data = covid)

# Workflows
data_wf_mtry2 <- workflow() %>%
  add_model(rf_spec %>% set_args(mtry = 2)) %>%
  add_recipe(rf_rec)

# Create workflows for mtry = 7, 22, and 44
data_wf_mtry7 <- workflow() %>%
  add_model(rf_spec %>% set_args(mtry = 7)) %>%
  add_recipe(rf_rec)

data_wf_mtry22 <- workflow() %>%
  add_model(rf_spec %>% set_args(mtry = 22)) %>%
  add_recipe(rf_rec)

data_wf_mtry44 <- workflow() %>%
  add_model(rf_spec %>% set_args(mtry = 44)) %>%
  add_recipe(rf_rec)
```

```{r}
# Fit Models

set.seed(123) # make sure to run this before each fit so that you have the same 1000 trees
data_fit_mtry2 <- fit(data_wf_mtry2, data = covid)

set.seed(123)
data_fit_mtry7 <- fit(data_wf_mtry7, data = covid)

set.seed(123) 
data_fit_mtry22 <- fit(data_wf_mtry22, data = covid)

set.seed(123)
data_fit_mtry44 <- fit(data_wf_mtry44, data = covid)
```

```{r}
# Custom Function to get OOB predictions, true observed outcomes and add a model label
rf_OOB_output <- function(fit_model, model_label, truth){
    tibble(
          .pred_continent = fit_model %>% extract_fit_engine() %>% pluck('predictions'), #OOB predictions
          continent = truth,
          model = model_label
      )
}

#check out the function output
rf_OOB_output(data_fit_mtry2,'mtry2', covid %>% pull(continent))
```

```{r}
# Evaluate OOB Metrics

data_rf_OOB_output <- bind_rows(
    rf_OOB_output(data_fit_mtry2,'mtry2', covid %>% pull(continent)),
    rf_OOB_output(data_fit_mtry7,'mtry7', covid %>% pull(continent)),
    rf_OOB_output(data_fit_mtry22,'mtry22', covid %>% pull(continent)),
    rf_OOB_output(data_fit_mtry44,'mtry44', covid %>% pull(continent))
)


data_rf_OOB_output %>% 
    group_by(model) %>%
    accuracy(truth = continent, estimate = .pred_continent)
```
```{r}
# Preliminary Interpretation

data_rf_OOB_output %>% 
    group_by(model) %>%
    accuracy(truth = continent, estimate = .pred_continent) %>%
  mutate(mtry = as.numeric(stringr::str_replace(model,'mtry',''))) %>%
  ggplot(aes(x = mtry, y = .estimate )) + 
  geom_point() +
  geom_line() +
  theme_classic()
```

```{r}
# Evaluating the forest

data_fit_mtry7
```

```{r}
rf_OOB_output(data_fit_mtry7,'mtry7', covid %>% pull(continent)) %>%
    conf_mat(truth = continent, estimate= .pred_continent)
```

```{r}
# Variable importance measures

data_fit_mtry7 %>% 
    extract_fit_engine() %>% 
    vip(num_features = 30) + theme_classic() #based on impurity
```


```{r}
data_wf_mtry7 %>% 
  update_model(rf_spec %>% set_args(importance = "permutation")) %>% #based on permutation
  fit(data = covid) %>% 
    extract_fit_engine() %>% 
    vip(num_features = 30) + theme_classic()
```

```{r}

## pick important variables to visualize

ggplot(covid, aes(x = continent, y = aged_70_older)) +
    geom_violin() + theme_classic()

ggplot(covid, aes(x = continent, y = total_vaccinations_per_hundred)) +
    geom_violin() + theme_classic()

ggplot(covid, aes(x = continent, y = total_deaths_per_million)) +
    geom_violin() + theme_classic()

ggplot(covid, aes(x = continent, y = total_cases)) +
    geom_violin() + theme_classic()

ggplot(covid, aes(x = continent, y = new_deaths_smoothed)) +
    geom_violin() + theme_classic()

```



## Classification - Methods

1. **Indicate at least 2 different methods used to answer your classification research question.**

Used logistic regression and random forests.

2. **Describe what you did to evaluate the models explored.**
3. **Indicate how you estimated quantitative evaluation metrics.**

For the logistic regression, we inspected the overall cross-validation results to determine the best lambda. We also determined the no-information-rate (NIR), which was 89%, meaning in this case that 89% of our cases represented "false (non-North America)" values. We also used the ROC curve to plot sensitivity (rate of true positive, predicting North American cases and North American) and specificity (true negative rate, predicting non-North-American cases as non-North American) of the overall model. It returned an ROC of 1, meaning it has essentially perfect prediction. Finally, we evaluated the model accuracy measure from our logistic quantitative output, which equaled .95, suggesting 95% predictive accuracy. 

For the decision tree, we used out-of-bag error (OOB) and the test confusion matrix. Our OOB returned as .02%, meaning the our model makes the wrong hard classification .02% of the time, which in our test confusion matrix is shown to be one wrong prediction. This suggests that the tree model has a 99.98% accuracy, making it slightly more accurate than the logistic model. However, this difference is within 5% accuracy, suggesting that either model could offer high predictive power in this research context. 


4. **Describe the goals / purpose of the methods used in the overall context of your research investigations.**

These methods were employed to predict the origin continent of each case.

## Classification - Results

1. **Summarize your final model and justify your model choice (see below for ways to justify your choice)**.
2. **Compare the different classification models tried in light of evaluation metrics, variable importance, and data context.**


These models also differ by metrics and variable importance. In the logistic regression, total cases, people vaccinated per hundred, and ICU patients proved to be among the most important variables. This is in contrast to the random forest model, which finds population age to generally be the most important predictor of new COVID cases.

We have selected the random forest model. This operates as a bagged decision tree, and can predict which continent each case is from. We selected this model for two reasons. First, and most importantly, this model can predict each content specifically, whereas the logistic model is restricted to a binary outcome of North America/Not North America. This a critical difference, as it allows for much more specific predictions within this data context. Secondly, this model has a slightly higher accuracy rating of 4.98%.





3. **Display evaluation metrics for different models in a clean, organized way. This display should include both the estimated metric as well as its standard deviation. (This won’t be available from OOB error estimation. If using OOB, don’t worry about reporting the SD.)**

all are listed above except standard deviation (ASK BRYAN DO NOT LEAVE THIS WHEN SUBMITTING)
4. **Broadly summarize conclusions from looking at these evaluation metrics and their measures of uncertainty.**

Overall the random forest model produces a more accurate prediction with fewer errors, and (ADD STANDARD DEVIATION STUFF HERE). The variables used are also different, focusing more on population demographic data than COVID data specifically. Finally, within the study context, this model also makes more sense due to the specificity of outcome it can offer via multiple-continent outcomes.  

## Classification - Conclusions

1. **Interpret evaluation metric(s) for the final model in context. Does the model show an acceptable amount of error?**

The model has an extremely low level of error, predicting results with 99.98% accuracy. This is far above any degree of predictive ability that could be expected, and is certainly an acceptable amount of error, especially considering the relatively low-stakes context of this study. 

2. **If using OOB error estimation, display the test (OOB) confusion matrix, and use it to interpret the strengths and weaknesses of the final model.**

```{r}
rf_OOB_output(data_fit_mtry7,'mtry7', covid %>% pull(continent)) %>%
    conf_mat(truth = continent, estimate= .pred_continent)
```

Here, we see that only one case has been incorrectly predicted in the training data, demonstrating the extreme predictive ability of this random forest model. 
3. **Summarization should show evidence of acknowledging the data context in thinking about the sensibility of these results.**

Overall, this model predicts with almost flawless accuracy the continent that each case of COVID data was collected in. In the context of this data, as well as the type of work which could draw on these findings, this model has successfully achieved its desired outcome. For medical professionals hoping to understand explanatory factors of COVID spread, or governments seeking to determine regional variation in explanatory factors, this model can provide direction with confidence.
